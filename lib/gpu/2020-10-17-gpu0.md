# gpu 0: Software rasterizer, part 1

I would like to design some hardware to accelerate raster graphics. However, I need to first have a better understanding of the subject. A good method for this may be to implement some of the [graphics pipeline](https://www.seas.upenn.edu/~cis565/LECTURES/Lecture2%20New.pdf) in software and put myself in the shoes of a graphics programmer in the 80s.

Let's jump into the middle of the pipeline and write a triangle rasterizer, which is a machine that turns triangles into pixels. From there we can expand out to both directions as needed.

At the beginning, I will follow [Triangle rasterization in practice](https://fgiesen.wordpress.com/2013/02/08/triangle-rasterization-in-practice) from ryg which explains the process very well. So, if this post comes across like a walkthrough of ryg's post, you know why.

I'll implement the rasterizer in javascript and use the browser canvas to draw. This way I can write it together with the blog post and have a "live code" environment.

<canvas id="c0" width="128" height="128">A javascript canvas.</canvas>
<script src="gpu0_0.js"></script>

Here we have some place to draw with chunky pixels and a grid to make error spotting easier. It's a 32x32 canvas scaled up by a factor of 4. I start with a triangle on canvas space coords (8, 28), (15, 3) and (25,10).

<canvas id="c1" width="128" height="128">A javascript canvas.</canvas>
<script src="gpu0_1.js"></script>

## 2D rasterizer

After looking at [The barycentric conspiracy](https://fgiesen.wordpress.com/2013/02/06/the-barycentric-conspirac/) for a little too long, I got that the basic technique is to calculate signed areas of every triangle formed by one edge of our original triangle and our point. If all are positive, the point lies to the left of all edges and should be painted. For the v<sub>10</sub> edge and the point p, the signed area is calculated as:

~~~
\begin{align*}
2A &= \vec{v}_{10} \times \vec{v}_{p0}\\
&= (v_{1x} - v_{0x}, v_{1y} - v_{0y}) \times (p_x - v_{0x}, p_y - v_{0y})\\
&= (v_{1x} - v_{0x})p_y + (v_{0y} - v_{1y})p_x + (v_{0x}v_{1y} - v_{1x}v_{0y})
\end{align*}
~~~

If p is to the left of v<sub>10</sub>, the v<sub>p0</sub> vector lies to the left of v<sub>10</sub> and the cross product should be positive from the right hand rule. (Our canvas Y grows downwards, so it works the other way: reverse the directions and hands.)

Another thing to note is that the _edge function_ which yields this signed area is affine, so you can just add (v<sub>1x</sub> - v<sub>0x</sub>) to the value calculated with p<sub>y</sub> and get the value for (p<sub>y</sub> + 1).

The other two edge functions are:

~~~
\begin{align*}
F_{12}(p) &:= (v_{1y} - v_{2y}) p_x + (v_{2x} - v_{1x}) p_y + (v_{1x} v_{2y} - v_{1y} v_{2x})\\
F_{20}(p) &:= (v_{2y} - v_{0y}) p_x + (v_{0x} - v_{2x}) p_y + (v_{2x} v_{0y} - v_{2y} v_{0x})
\end{align*}
~~~

So, let's implement this in a bunch of javascript.

```
function edge_fn(v0, v1, p){
    return (v0.y - v1.y)*p.x + (v1.x - v0.x)*p.y + (v0.x*v1.y - v1.x*v0.y);
}

ctx2.fillStyle="#f00";
for(var i=0; i<32; i++){
    for(var j=0; j<32; j++){
        p = {x: i, y: j};
        if(edge_fn(v0, v1, p) >= 0 &&
            edge_fn(v1, v2, p) >= 0 &&
            edge_fn(v2, v0, p) >= 0){
            /* put pixel */
            ctx2.fillRect(i, j, 1, 1);
        }
    }
}
```

The output is, uh, a triangle:

<canvas id="c2" width="128" height="128">A javascript canvas.</canvas>
<script src="gpu0_2.js"></script>

There is nothing wrong with this piece of code except that it's slow and incorrect. It computes the whole edge function for every pixel, samples from the wrong point of the pixel and does not apply any _fill rules_.

Let's add a bigger pixel grid with marked pixel centers like [this guide](https://docs.microsoft.com/en-us/windows/win32/direct3d11/d3d10-graphics-programming-guide-rasterizer-stage-rules) and check what's wrong with our basic approach. By the way, I didn't know the Microsoft programming guide for D3D11 included a full description of the graphics pipeline with nice illustrations. A new addition to the reading list.

Here are the lit-up pixels with our approach:

<canvas id="c3" width="256" height="128">A javascript canvas.</canvas>
<script src="gpu0_3.js"></script>

You can see that it's quite off since we are sampling from the top lefts of the pixels. I think 1 bit of sub-pixel precision is enough to sample pixels from the middle. However, we can go all the way and put 8 bits of sub-pixel precision as required by DX11.

```
var step = 256;

for(var i = step/2; i < 16*step; i += step){
    for(var j = step/2; j < 8*step; j += step){
        p = {x: i, y: j};
        if(edge_fn(v0, v1, p) >= 0 &&
            edge_fn(v1, v2, p) >= 0 &&
            edge_fn(v2, v0, p) >= 0){
            put_pixel(p);
        }
    }
}
```

This looks much better:

<canvas id="c4" width="256" height="128">A javascript canvas.</canvas>
<script src="gpu0_4.js"></script>

Next, fill rules. To demonstrate, I'll add a shape from the D3D10 guide. Our rasterizer currently draws the shape like this:

<canvas id="c5" width="256" height="128">A javascript canvas.</canvas>
<script src="gpu0_5.js"></script>

As you can see, the middle 3 pixels are colored twice. That is what fill rules should be preventing. They come into work when the edge of a triangle crosses the middle of a pixel, i.e. the edge function is 0 at that point:

> Any pixel center which falls inside a triangle is drawn; a pixel is assumed to be inside if it passes the top-left rule. The top-left rule is that a pixel center is defined to lie inside of a triangle if it lies on the top edge or the left edge of a triangle.
>
> Where:<ul>
> <li>A top edge, is an edge that is exactly horizontal and is above the other edges.</li>
> <li>A left edge, is an edge that is not exactly horizontal and is on the left side of the triangle. A triangle can have one or two left edges.</li>

This looks confusing, but they get easier if we consider triangles wound in only one direction. For clockwise triangles (as in our canvas coords):

* A top edge is an edge that is exactly horizontal and goes to the right. (Otherwise we get a CCW triangle.)
* A left edge is an edge that goes up. Since it goes up, it can't be exactly horizontal.

Let's go ahead and write the code. We'll add a bias value of -1 for non top-left edges. That will prevent drawing of the pixel in case the edge function ends up at 0.

I also see this as an opportunity to add more triangles and make a per-triangle loop.

```
function is_top_left(v0, v1){
    if(v0.y == v1.y && v0.x < v1.x) return true;
    else if(v0.y > v1.y) return true;
    else return false;
}

for(var i = 0; i < trigs.length; i++){
    t = trigs[i];
    for(var x = step/2; x < 16*step; x += step){
        for(var y = step/2; y < 8*step; y += step){
            var p = {x: x, y: y};
            var bias0 = is_top_left(t.v1, t.v2) ? 0 : -1;
            var bias1 = is_top_left(t.v2, t.v0) ? 0 : -1;
            var bias2 = is_top_left(t.v0, t.v1) ? 0 : -1;
            var w0 = edge_fn(t.v1, t.v2, p) + bias0;
            var w1 = edge_fn(t.v2, t.v0, p) + bias1;
            var w2 = edge_fn(t.v0, t.v1, p) + bias2;
            if(w0 >= 0 && w1 >= 0 && w2 >= 0){
                ctx6.fillStyle = t.style;
                put_pixel(p);
            }
        }
    }
}
```

Now the result should be identical to the [one](https://docs.microsoft.com/en-us/windows/win32/direct3d11/images/d3d10-rasterrulestriangle.png) in the D3D10 guide. Actually, let's add a few more shapes from the guide to check if they get rasterized correctly:

<canvas id="c6" width="256" height="128">A javascript canvas.</canvas>
<script src="gpu0_6.js"></script>

Looks OK. After we get here, ryg goes on to optimize this rasterizer, but I think we should first get to perspective projection. If we complete that part of the pipeline, we can draw more complex 3D scenes which will eventually require a fast rasterizer.

## Perspective projection

In my opinion, the best part of raster graphics is that you can just paste a 3D scene onto the screen and work there with a series of linear interpolations. At least, this is my view as someone who only knows about ray tracing.

(I will be following chapter 18 of [this 1996 book](https://www.amazon.com/Jim-Blinns-Corner-Graphics-Pipeline/dp/1558603875), [this post](http://simonstechblog.blogspot.com/2012/04/software-rasterizer-part-1.html) from Simon and [this WebGL guide](http://learnwebgl.brown37.net/08_projections/projections_perspective.html) for this section.)

On a closer look, it seems like that small _pasting 3D to 2D_ step is a little complicated. We have to first convert to a _clip space_, do clipping and then convert to viewport coordinates. Furthermore, the transform is done in 4D projective space, something I have never had to think about in ray tracing. In ray tracing everything is 3D and the scene clips itself...

I had a hard time wrapping my head around how we embed the properties of our viewing frustum into the perspective transform matrix. How do we move the camera?  Where is the near plane? Far plane? The mapping to clip space? It took some staring at the resources to get a hold of the situation. To quote the steps of the transformation from the WebGL guide:

> We need to perform the following steps to create a perspective projection transformation matrix:
> <ol><li>Translate the apex of the frustum to the origin.</li>
> <li>Perform the perspective calculation.</li>
> <li>Scale the 2D (x’,y’) values in the viewing window to a 2-by-2 unit square: (-1,-1) to (+1,+1).</li>
> <li>Scale the depth values (z) into a normalized range (-1,+1).</li>
> <li>Flip the orientation of the z axis to match the clipping volume’s orientation.</li></ol>

The tricky steps here are 2 and 4. Step 2 is easier than it looks, it's the old triangle similarity math which turns X into ~$\frac{Xn}{-Z}$~. Here, ~$n$~ is the near plane distance and Z is negative since the camera is assumed to be looking down the -Z direction.

~~~
\begin{equation*}
\begin{bmatrix}
n & 0 & 0 & 0\\
0 & n & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & -1 & 0
\end{bmatrix}
\begin{bmatrix}
X\\
Y\\
Z\\
1\\
\end{bmatrix}
=
\begin{bmatrix}
Xn\\
Yn\\
Z\\
-Z
\end{bmatrix}
\end{equation*}
~~~

Step 4 should map Z to 0 (for DirectX, -1 for OpenGL) at the near plane and 1 at the far plane instead of locking it to -1. That requires some tuning of the matrix parameters.

~~~
\begin{equation*}
\begin{gathered}
\begin{bmatrix}
n & 0 & 0 & 0\\
0 & n & 0 & 0\\
0 & 0 & A & B\\
0 & 0 & -1 & 0
\end{bmatrix}
\begin{bmatrix}
0\\
0\\
-n\\
1\\
\end{bmatrix}
=
\begin{bmatrix}
0\\
0\\
-An+B\\
-n
\end{bmatrix}\\
-An+B = 0\\
B = An\\
\end{gathered}
\end{equation*}
~~~

Then we map the far plane `z = -f` to `z = 1`:

~~~
\begin{equation*}
\begin{gathered}
\begin{bmatrix}
n & 0 & 0 & 0\\
0 & n & 0 & 0\\
0 & 0 & A & An\\
0 & 0 & -1 & 0
\end{bmatrix}
\begin{bmatrix}
0\\
0\\
-f\\
1\\
\end{bmatrix}
=
\begin{bmatrix}
0\\
0\\
-Af + An\\
f
\end{bmatrix}\\
\frac{An - Af}{f} = 1\\
A = \frac{f}{n - f}\\
\end{gathered}
\end{equation*}
~~~

Let's finally apply the viewport mapping to (-1, +1) and assume the camera has no XY offset. This brings us to our final perspective transform matrix:

~~~
\begin{equation*}
\begin{bmatrix}
\frac{2n}{V_w} & 0 & 0 & 0\\
0 & \frac{2n}{V_h} & 0 & 0\\
0 & 0 & \frac{f}{n-f} & \frac{nf}{n-f}\\
0 & 0 & -1 & 0
\end{bmatrix}
\end{equation*}
~~~

This matrix takes us to the _clip space_. After clipping we normalize by `w` and then map X and Y to the viewport coordinates. The resulting _screen space_ is probably where our rasterizer should work. (Not the canvas coords!)

For the first test, I am going to use the camera and vertex data from the scene in [rt 1](../rt/2017-03-11-assign1.html). The scene only has some shapes on the Z=-2 plane, so it shouldn't require clipping or depth buffering. (Ignoring the sphere for now.)

```
var cam = {vw: 2, vh: 2, near: 1, far: 100};

function proj_mtx(vw, vh, n, f){
    return [
        [2*n/vw, 0, 0, 0],
        [0, 2*n/vh, 0, 0],
        [0, 0, f/(n-f), n*f/(n-f)],
        [0, 0, -1, 0]
    ];
}

function viewport(v, w, h){
    return [(v[0]+1)*w/2, (v[1]+1)*h/2, v[2], v[3]];
}

function wnorm(v){
    return [v[0]/v[3], v[1]/v[3], v[2]/v[3], 1];
}

var P = proj_mtx(cam.vw, cam.vh, cam.near, cam.far);

var verts_vp = [];
for(var i=0; i<verts.length; i++){
	var v = verts[i];
	var v_clip = mat4x4_mul_vec4(P, v);
	var v_vp = viewport(wnorm(v_clip), 128, 128);
	verts_vp.push(v_vp);
}

/* draw triangles */
...
```

<canvas id="c7" width="128" height="128">A javascript canvas.</canvas>
<script src="gpu0_7.js"></script>

Looks like our matrix worked: vertices are at the right coords. [Here](../rt/simple.png) is the ray tracer's rendering of the scene for comparison. Let's get back to the rasterizer now.

An issue is how to apply sub-pixel precision. Up there we just multiplied every coordinate by 256. Turns out that can be better handled in the rasterizer if we add edge function stepping and handle sub-pixel precision in the setup phase. (See [ryg's post](https://fgiesen.wordpress.com/2013/02/10/optimizing-the-basic-rasterizer/) for details.) It's also a good time to switch from canvas coords to screen coords, which should only change the top-left edge rules.

```
function draw_trig(v0, v1, v2){
    var step = 256;

    /* F = Ax + By + C */
    var A01 = step * (v0[1] - v1[1]);
    var A12 = step * (v1[1] - v2[1]);
    var A20 = step * (v2[1] - v0[1]);
    var B01 = step * (v1[0] - v0[0]);
    var B12 = step * (v2[0] - v1[0]);
    var B20 = step * (v0[0] - v2[0]);
    var C01 = step * (v0[0]*v1[1] - v0[1]*v1[0]);
    var C12 = step * (v1[0]*v2[1] - v1[1]*v2[0]);
    var C20 = step * (v2[0]*v0[1] - v2[1]*v0[0]);

    /* fill rules */
    var bias0 = is_top_left(v1, v2) ? 0 : -1;
    var bias1 = is_top_left(v2, v0) ? 0 : -1;
    var bias2 = is_top_left(v0, v1) ? 0 : -1;

    /* start from x=1/2, y=1/2 */
    var w0_row = C12 + A12/2 + B12/2 + bias0;
    var w1_row = C20 + A20/2 + B20/2 + bias1;
    var w2_row = C01 + A01/2 + B01/2 + bias2;
    for(var y=0; y<128; y++){
        var w0 = w0_row;
        var w1 = w1_row;
        var w2 = w2_row;
        for(var x=0; x<128; x++){
            if(w0 >= 0 && w1 >= 0 && w2 >= 0){
                put_pixel(x, y);
            }
            w0 += A12;
            w1 += A20;
            w2 += A01;
        }
        w0_row += B12;
        w1_row += B20;
        w2_row += B01;
    }
}
```

This method of sub-pixel precision is different and I'm not sure if I did it right, but the idea goes like this: We are stepping this function in terms of A and B values, and it should be enough to add 8 bits of precision to the step values. Multiplying all coords by 256 effectively adds 16 bits of precision to the steps.

And, here is the result on a 128x128 canvas. (The triangle is too small for the 32x32 one.)

<canvas id="c8" width="128" height="128">A javascript canvas.</canvas>
<script src="gpu0_8.js"></script>

I think this is officially the longest path to drawing a square and a triangle on a javascript canvas :) Anyway, we have still a long way to go in the pipeline: we still don't have clipping, depth buffering, textures etc., and our rasterizer is still not very optimized. We will deal with those in the next post. See you until then!
